from __future__ import annotations

import random
import glob
import os
from datetime import datetime, timezone
from typing import Dict, List, Optional

from fastapi import FastAPI, Query, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse


BACKEND_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.normpath(os.path.join(BACKEND_DIR, ".."))
DATA_ROOT = os.path.join(PROJECT_ROOT, "CA_data")


app = FastAPI(title="TerraNova Demo API", version="0.2.0")

app.add_middleware(
  CORSMiddleware,
  allow_origins=["*"],
  allow_methods=["*"],
  allow_headers=["*"],
)


FIRE_CATALOG: List[Dict] = [
  {
    "id": "camp-fire-2018",
    "name": "Camp Fire",
    "state": "CA",
    "lat": 39.73,
    "lng": -121.6,
    "acres": 153_336,
    "start_date": "2018-11-08",
    "cause": "Electrical",
    "summary": "Largest loss of life in CA wildfire history; Paradise community heavily impacted.",
    "perimeter_radius": 25000,
    "region": "Paradise & Magalia",
    "zipcode": "95969",
  },
  {
    "id": "dixie-fire-2021",
    "name": "Dixie Fire",
    "state": "CA",
    "lat": 40.18,
    "lng": -121.23,
    "acres": 963_309,
    "start_date": "2021-07-13",
    "cause": "Powerline",
    "summary": "Second-largest CA wildfire; complex terrain through Plumas and Lassen counties.",
    "perimeter_radius": 36000,
    "region": "Feather River Watershed",
    "zipcode": "95954",
  },
  {
    "id": "bootleg-fire-2021",
    "name": "Bootleg Fire",
    "state": "OR",
    "lat": 42.56,
    "lng": -121.5,
    "acres": 413_765,
    "start_date": "2021-07-06",
    "cause": "Lightning",
    "summary": "Major fire in southern Oregon; threatened critical transmission corridors.",
    "perimeter_radius": 28000,
    "region": "Fremont-Winema NF",
    "zipcode": "97620",
  },
  {
    "id": "maui-fire-2023",
    "name": "Lahaina Wildfire",
    "state": "HI",
    "lat": 20.88,
    "lng": -156.68,
    "acres": 6_700,
    "start_date": "2023-08-08",
    "cause": "Under investigation",
    "summary": "Urban-interface fire on Maui with catastrophic impacts to Lahaina town.",
    "perimeter_radius": 12000,
    "region": "West Maui",
    "zipcode": "96761",
  },
  {
    "id": "hurricane-fire-2024",
    "name": "Hurricane Fire",
    "state": "CA",
    "lat": 35.195,
    "lng": -119.656,
    "acres": 13_488,
    "start_date": "2024-07-13",
    "cause": "Under investigation",
    "summary": "2024 wildfire in California, mapped by MTBS with Sentinel-2A imagery.",
    "perimeter_radius": 15000,
    "region": "California",
    "zipcode": "93240",
    "mtbs_event_id": "ca3519911969620240713",
  },
  {
    "id": "canyon-fire-2016",
    "name": "Canyon Fire",
    "state": "CA",
    "lat": 34.597,
    "lng": -120.584,
    "acres": 12_749,
    "start_date": "2016-09-18",
    "cause": "Under investigation",
    "summary": "2016 wildfire in California, mapped by MTBS with Landsat 8 OLI imagery (Extended assessment).",
    "perimeter_radius": 14000,
    "region": "California",
    "zipcode": "93436",
    "mtbs_event_id": "ca3472012055020160918",
  },
]

FIRE_LOOKUP: Dict[str, Dict] = {fire["id"]: fire for fire in FIRE_CATALOG}

TIMELINE_STAGES = [
  {"value": 0, "label": "Pre-fire baseline", "description": "Vegetation health before ignition", "days_from_ignition": -30},
  {"value": 1, "label": "Active response (Day 0)", "description": "Fire perimeter with live suppression actions", "days_from_ignition": 0},
  {"value": 2, "label": "Initial assessment (Day 7)", "description": "First MTBS-inspired burn severity mapping", "days_from_ignition": 7},
  {"value": 3, "label": "Stabilization phase (Day 30)", "description": "Treatment crews in the field; erosion control active", "days_from_ignition": 30},
  {"value": 4, "label": "Recovery outlook (Year 1)", "description": "Predicted vegetation recovery and infrastructure repairs", "days_from_ignition": 365},
]


def clamp(value: float, low: float = 0.0, high: float = 1.0) -> float:
  return max(low, min(high, value))


def pick_fire(fire_id: Optional[str]) -> Dict:
  if fire_id and fire_id in FIRE_LOOKUP:
    return FIRE_LOOKUP[fire_id]
  return FIRE_CATALOG[0]


def parse_priority(value: Optional[float], fallback: float) -> float:
  if value is None:
    value = fallback
  return clamp(float(value) / 100.0, 0.05, 1.0)


def normalize_priorities(raw: Dict[str, float]) -> Dict[str, float]:
  total = sum(raw.values())
  if total == 0:
    return {k: 1 / len(raw) for k in raw}
  return {k: v / total for k, v in raw.items()}


def jitter_coords(lat: float, lng: float, delta: float = 0.18) -> List[float]:
  return [
    round(lat + random.uniform(-delta, delta), 4),
    round(lng + random.uniform(-delta, delta), 4),
  ]


def get_timeline_meta(stage: int) -> Dict:
  idx = clamp(stage, 0, len(TIMELINE_STAGES) - 1)
  return TIMELINE_STAGES[int(idx)]


def generate_hotspots(fire: Dict) -> List[Dict]:
  base_lat, base_lng = fire["lat"], fire["lng"]
  hotspots = []
  for idx in range(3):
    coords = jitter_coords(base_lat, base_lng, delta=0.25)
    hotspots.append({
      "id": f"{fire['id']}-sector-{idx}",
      "title": f"Sector {idx + 1}",
      "details": random.choice([
        "Watershed slopes showing hydrophobic soils.",
        "Dense structure grid; ember threat remains.",
        "Steep canyon with unstable ash covering.",
        "Riparian corridor experiencing debris deposition.",
      ]),
      "coords": coords,
    })
  return hotspots


def generate_layers(fire: Dict, timeline_meta: Dict, priorities: Dict[str, float]) -> Dict[str, List[Dict]]:
  stage_index = timeline_meta["value"]
  decay = 1 - (stage_index / (len(TIMELINE_STAGES) - 1)) * 0.55
  layers: Dict[str, List[Dict]] = {
    "burnSeverity": [],
    "reburnRisk": [],
    "bestNextSteps": [],
  }

  color_map = {
    "burnSeverity": "#ff4e1f",
    "reburnRisk": "#ff6b35",
    "bestNextSteps": "#4ecdc4",
  }

  base_radius = fire["perimeter_radius"]
  center_lat, center_lng = fire["lat"], fire["lng"]

  for layer_key in layers.keys():
    weight = priorities.get({
      "burnSeverity": "community",
      "reburnRisk": "community",
      "bestNextSteps": "community",
    }[layer_key], 0.25)

    for _ in range(2):
      coords = jitter_coords(center_lat, center_lng, delta=0.22)
      radius = int(base_radius * (0.6 + weight * 0.8) * decay * random.uniform(0.8, 1.2))
      intensity = clamp((0.55 + weight * 0.5) * decay + random.uniform(-0.08, 0.08))
      layers[layer_key].append({
        "coords": coords,
        "radius": max(8000, radius),
        "color": color_map[layer_key],
        "intensity": round(intensity, 2),
      })

  return layers


def summarize_priorities(priorities: Dict[str, float]) -> List[Dict]:
  labels = {
    "community": "Community safety",
    "watershed": "Watershed health",
    "infrastructure": "Infrastructure readiness",
  }
  summaries = {
    "community": "Focus on structure protection and WUI buffers.",
    "watershed": "Stabilize slopes and protect drinking water sheds.",
    "infrastructure": "Keep roads, utilities, and comms online.",
  }
  result = []
  for key, value in priorities.items():
    result.append({
      "label": labels[key],
      "score": round(value * 100),
      "summary": summaries[key],
    })
  result.sort(key=lambda item: item["score"], reverse=True)
  return result


def generate_next_steps(fire: Dict, priorities: Dict[str, float], timeline_meta: Dict) -> List[str]:
  top_priority = max(priorities, key=priorities.get)
  steps = []
  if top_priority == "community":
    steps.append(f"Pre-position structure protection crews along the {fire['region']} fringe.")
    steps.append("Activate text alerts that explain road closures in plain language.")
  elif top_priority == "watershed":
    steps.append("Deploy BAER teams to seed and mulch high-severity headwaters.")
    steps.append("Stage portable sediment traps to guard downstream intakes.")
  else:
    steps.append("Inspect primary transmission corridors and backup fiber routes.")
    steps.append("Schedule quick-build repairs for scorched culverts and bridges.")

  steps.append(f"Update the {timeline_meta['label'].lower()} briefing and push to local EOCs.")
  return steps


def generate_insights(fire: Dict, timeline_meta: Dict) -> List[Dict]:
  return [
    {
      "category": "Action",
      "title": "Crew routing",
      "detail": f"Assign crews to {fire['region']} ridge within {timeline_meta['label'].split()[0]} window.",
    },
    {
      "category": "Monitoring",
      "title": "Hydrology sensors",
      "detail": "4 gauges tripped thresholds; auto-sync data every 15 minutes.",
    },
    {
      "category": "Community",
      "title": "Next briefing",
      "detail": "Upload narrated map to public viewer and share short link.",
    },
  ]


def format_stats(fire: Dict) -> Dict:
  # Weather conditions (dummy data for now)
  temps = [68, 72, 75, 78, 82, 85]
  conditions = ["Clear", "Partly Cloudy", "Sunny", "Windy"]
  temp = random.choice(temps)
  condition = random.choice(conditions)
  weather = f"{temp}°F, {condition}"
  
  # Reburn risk (dummy data - will be calculated later based on burn history)
  # For now, randomly assign High/Medium/Low
  risk_levels = ["High", "Medium", "Low"]
  risk_weights = [0.3, 0.5, 0.2]  # 30% High, 50% Medium, 20% Low
  reburn_risk = random.choices(risk_levels, weights=risk_weights)[0]
  
  incidents = random.randint(3, 8)
  updated = f"{fire['region']} · Updated {random.randint(15, 80)} mins ago"
  return {
    "weather": weather,
    "reburnRisk": reburn_risk,
    "incidents": incidents,
    "updated": updated,
    "acres": fire["acres"],
  }


@app.get("/api/fires")
async def list_fires(
  state: Optional[str] = Query(None, description="Filter by state code (e.g., CA, OR)"),
  year: Optional[int] = Query(None, description="Filter by year"),
):
  """
  Returns list of fires, optionally filtered by state and year.
  Results are sorted by most recent first.
  """
  filtered_fires = FIRE_CATALOG.copy()
  
  # Apply filters
  if state:
    state_upper = state.upper().strip()
    filtered_fires = [f for f in filtered_fires if f["state"].upper() == state_upper]
  
  if year:
    filtered_fires = [
      f for f in filtered_fires 
      if f["start_date"] and int(f["start_date"].split("-")[0]) == year
    ]
  
  # Sort by year descending (newest first), then by date within same year
  def get_sort_key(fire: Dict) -> tuple:
    date_str = fire.get("start_date", "") or ""
    if date_str:
      try:
        # Extract year, month, day for proper sorting
        parts = date_str.split("-")
        if len(parts) >= 3:
          year = int(parts[0])
          month = int(parts[1])
          day = int(parts[2])
          # Return tuple for sorting: (-year, -month, -day) for descending order
          return (-year, -month, -day)
      except (ValueError, IndexError):
        pass
    return (0, 0, 0)  # Put fires without dates at the end
  
  sorted_fires = sorted(filtered_fires, key=get_sort_key)
  
  return {"fires": sorted_fires}


@app.get("/api/scenario")
async def get_scenario(
  fireId: Optional[str] = Query(None, description="Fire identifier"),
  timeline: int = Query(2, ge=0, le=4),
  priorityCommunity: int = Query(70, ge=0, le=100),
  priorityWatershed: int = Query(55, ge=0, le=100),
  priorityInfrastructure: int = Query(60, ge=0, le=100),
):
  fire = pick_fire(fireId)
  timeline_meta = get_timeline_meta(timeline)

  raw_priorities = {
    "community": parse_priority(priorityCommunity, 70),
    "watershed": parse_priority(priorityWatershed, 55),
    "infrastructure": parse_priority(priorityInfrastructure, 60),
  }
  normalized_priorities = normalize_priorities(raw_priorities)

  layers = generate_layers(fire, timeline_meta, normalized_priorities)
  priorities_summary = summarize_priorities(normalized_priorities)
  hotspots = generate_hotspots(fire)
  next_steps = generate_next_steps(fire, normalized_priorities, timeline_meta)
  insights = generate_insights(fire, timeline_meta)
  stats = format_stats(fire)

  response = {
    "fire": {
      "id": fire["id"],
      "name": fire["name"],
      "state": fire["state"],
      "region": fire["region"],
      "summary": fire["summary"],
      "acres": fire["acres"],
      "startDate": fire["start_date"],
      "cause": fire["cause"],
      "center": [fire["lat"], fire["lng"]],
    },
    "timeline": timeline_meta,
    "stats": stats,
    "layers": layers,
    "markers": hotspots,
    "priorities": priorities_summary,
    "nextSteps": next_steps,
    "insights": insights,
    "mapTip": f"{timeline_meta['label']} · {timeline_meta['description']}",
    "generatedAt": datetime.now(timezone.utc).isoformat(),
  }
  return response


@app.get("/api/ask")
async def ask_about_fire(fireId: str = Query("camp-fire-2018"), question: str = Query("")):
  """
  Simple LLM-style Q&A endpoint that returns plain-language fire summaries.
  In production, replace this with actual LLM calls (OpenAI, Anthropic, etc.).
  """
  fire_info = next((f for f in FIRE_CATALOG if f["id"] == fireId), FIRE_CATALOG[0])
  
  # Template-based responses for common questions
  question_lower = question.lower()
  
  if "cause" in question_lower or "start" in question_lower or "ignit" in question_lower:
    answer = f"The {fire_info['name']} started on {fire_info['startDate']} in {fire_info['region']}, {fire_info['state']}. The cause was determined to be {fire_info['cause'].lower()}."
  
  elif "damage" in question_lower or "severe" in question_lower or "impact" in question_lower:
    answer = f"The {fire_info['name']} burned approximately {fire_info['acres']:,} acres. {fire_info['summary']} Our burn severity model classifies the area into high, moderate, and low severity zones to help prioritize recovery efforts."
  
  elif "when" in question_lower or "date" in question_lower:
    answer = f"The {fire_info['name']} ignited on {fire_info['startDate']}. The initial MTBS-style assessment typically occurs within 7 days of ignition, with follow-up mapping at 30 days and long-term recovery tracking extending to 1-5 years."
  
  elif "where" in question_lower or "location" in question_lower:
    answer = f"The {fire_info['name']} occurred in {fire_info['region']}, {fire_info['state']}. You can see the exact location on the map above, with burn severity overlays showing the spatial extent of damage."
  
  elif "recovery" in question_lower or "rehab" in question_lower or "restoration" in question_lower:
    answer = f"Recovery from the {fire_info['name']} is ongoing. Our model tracks burn severity changes over time, helping land managers prioritize watershed stabilization, erosion control, and vegetation reseeding. Adjust the forecast slider to see predicted recovery at different time horizons."
  
  elif "model" in question_lower or "algorithm" in question_lower or "how" in question_lower:
    answer = f"Our burn severity segmentation model analyzes Landsat imagery to classify each 30m pixel as unburned, low, moderate, or high severity. The model was trained on MTBS reference data and uses spectral indices (NDVI, NBR) to detect vegetation loss. The priority sliders let you weight community safety, watershed health, and infrastructure concerns to customize the analysis."
  
  else:
    answer = f"The {fire_info['name']} burned {fire_info['acres']:,} acres in {fire_info['region']}, {fire_info['state']}, starting {fire_info['startDate']}. Cause: {fire_info['cause']}. {fire_info['summary']} Use the map controls to explore burn severity layers, adjust priorities, and see how conditions change over time. Ask more specific questions about the fire's cause, damage, location, recovery, or our modeling approach."
  
  return {
    "fireId": fireId,
    "question": question,
    "answer": answer,
    "generatedAt": datetime.now(timezone.utc).isoformat(),
  }


@app.get("/api/burn-severity/{fire_id}.tif")
async def get_burn_severity_raster(fire_id: str):
  """
  Returns MTBS GeoTIFF raster file (dnbr6.tif) for burn severity.
  
  Maps fire_id to MTBS event_id and finds the dnbr6.tif file.
  """
  fire = pick_fire(fire_id)
  mtbs_event_id = fire.get("mtbs_event_id")
  
  if not mtbs_event_id:
    raise HTTPException(
      status_code=404,
      detail=f"No MTBS data available for fire: {fire_id}"
    )
  
  # GeoTIFF data now lives under UI_TEST3/CA_data/{mtbs_event_id}
  ca_data_dir = os.path.join(DATA_ROOT, mtbs_event_id)
  
  if not os.path.exists(ca_data_dir):
    raise HTTPException(
      status_code=404,
      detail=f"MTBS data directory not found: {ca_data_dir}"
    )
  
  # Look for dnbr6.tif file (pattern: {event_id}_*_dnbr6.tif)
  pattern = os.path.join(ca_data_dir, f"{mtbs_event_id}_*_dnbr6.tif")
  matching_files = glob.glob(pattern)
  
  if not matching_files:
    raise HTTPException(
      status_code=404,
      detail=f"MTBS burn severity raster (dnbr6.tif) not found for fire: {fire_id}"
    )
  
  file_path = matching_files[0]  # Use first match
  
  return FileResponse(
    file_path,
    media_type="image/tiff",
    headers={
      "Content-Disposition": f"inline; filename={fire_id}_burn_severity.tif",
      "Access-Control-Allow-Origin": "*"
    }
  )


@app.get("/api/reburn-risk/{fire_id}.tif")
async def get_reburn_risk_raster(fire_id: str):
  """
  Returns GeoTIFF raster file for reburn risk classification.
  Maps fire_id to MTBS event_id and finds the reburn_risk.tif file.
  """
  fire = pick_fire(fire_id)
  mtbs_event_id = fire.get("mtbs_event_id")
  
  if not mtbs_event_id:
    raise HTTPException(
      status_code=404,
      detail=f"No MTBS data available for fire: {fire_id}"
    )
  
  # GeoTIFF data now lives under UI_TEST3/CA_data/{mtbs_event_id}
  ca_data_dir = os.path.join(DATA_ROOT, mtbs_event_id)
  
  if not os.path.exists(ca_data_dir):
    raise HTTPException(
      status_code=404,
      detail=f"MTBS data directory not found: {ca_data_dir}"
    )
  
  # Look for reburn_risk.tif file (pattern: {event_id}_*_reburn_risk.tif)
  pattern = os.path.join(ca_data_dir, f"{mtbs_event_id}_*_reburn_risk.tif")
  matching_files = glob.glob(pattern)
  
  if not matching_files:
    raise HTTPException(
      status_code=404,
      detail=f"Reburn risk raster not found for fire: {fire_id}"
    )
  
  file_path = matching_files[0]  # Use first match
  
  return FileResponse(
    file_path,
    media_type="image/tiff",
    headers={
      "Content-Disposition": f"inline; filename={fire_id}_reburn_risk.tif",
      "Access-Control-Allow-Origin": "*"
    }
  )


@app.get("/api/best-next-steps/{fire_id}.tif")
async def get_best_next_steps_raster(fire_id: str):
  """
  Returns GeoTIFF raster file for best next steps classification (grid-based).
  Maps fire_id to MTBS event_id and finds the best_next_steps_grid.tif file.
  """
  fire = pick_fire(fire_id)
  mtbs_event_id = fire.get("mtbs_event_id")
  
  if not mtbs_event_id:
    raise HTTPException(
      status_code=404,
      detail=f"No MTBS data available for fire: {fire_id}"
    )
  
  # GeoTIFF data now lives under UI_TEST3/CA_data/{mtbs_event_id}
  ca_data_dir = os.path.join(DATA_ROOT, mtbs_event_id)
  
  if not os.path.exists(ca_data_dir):
    raise HTTPException(
      status_code=404,
      detail=f"MTBS data directory not found: {ca_data_dir}"
    )
  
  # Look for best_next_steps_grid.tif file (prefer grid version)
  pattern_grid = os.path.join(ca_data_dir, f"{mtbs_event_id}_*_best_next_steps_grid.tif")
  matching_files = glob.glob(pattern_grid)
  
  # Fallback to non-grid version if grid doesn't exist
  if not matching_files:
    pattern = os.path.join(ca_data_dir, f"{mtbs_event_id}_*_best_next_steps.tif")
    matching_files = glob.glob(pattern)
  
  if not matching_files:
    raise HTTPException(
      status_code=404,
      detail=f"Best next steps raster not found for fire: {fire_id}"
    )
  
  file_path = matching_files[0]  # Use first match
  
  return FileResponse(
    file_path,
    media_type="image/tiff",
    headers={
      "Content-Disposition": f"inline; filename={fire_id}_best_next_steps.tif",
      "Access-Control-Allow-Origin": "*"
    }
  )


@app.get("/api/health")
async def health_check():
  return {"status": "ok", "timestamp": datetime.now(timezone.utc).isoformat()}

